<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts | Xijia</title>
    <link>https://xijia.me/post/</link>
      <atom:link href="https://xijia.me/post/index.xml" rel="self" type="application/rss+xml" />
    <description>Posts</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Mon, 02 Oct 2023 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://xijia.me/media/icon_hud0878d03dbfef15a826247f760be8539_121126_512x512_fill_lanczos_center_3.png</url>
      <title>Posts</title>
      <link>https://xijia.me/post/</link>
    </image>
    
    <item>
      <title>Paper Accepted at IROS 2023 Human Multi-Robot Interaction Workshop</title>
      <link>https://xijia.me/post/iros/</link>
      <pubDate>Mon, 02 Oct 2023 00:00:00 +0000</pubDate>
      <guid>https://xijia.me/post/iros/</guid>
      <description>&lt;p&gt;I am excited to announce that my paper has been accepted for presentation at the Human Multi-Robot Interaction Workshop, part of the International Conference on Intelligent Robots and Systems (IROS) 2023, in Detroit. This acceptance marks a significant milestone in my research career and contributes to the growing body of knowledge in the field of robotics.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/iros/iros_hub9e39c845635529cf040b4b5be80d140_63613_de0a7ce714e60525b842c8b206286c2c.webp 400w,
               /post/iros/iros_hub9e39c845635529cf040b4b5be80d140_63613_32d33dd27dbb905e4d04886dba0a26fe.webp 760w,
               /post/iros/iros_hub9e39c845635529cf040b4b5be80d140_63613_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://xijia.me/post/iros/iros_hub9e39c845635529cf040b4b5be80d140_63613_de0a7ce714e60525b842c8b206286c2c.webp&#34;
               width=&#34;720&#34;
               height=&#34;540&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Intelligent agents such as robots are increasingly deployed in real-world, safety-critical settings. It is vital that these agents are able to explain the reasoning behind their decisions to human counterparts, however, their behavior is often produced by uninterpretable models such as deep neural networks. We propose an approach to generate natural language explanations for an agent&amp;rsquo;s behavior based only on observations of states and actions, agnostic to the underlying model representation. We show how a compact representation of the agent&amp;rsquo;s behavior can be learned and used to produce plausible explanations with minimal hallucination while affording user interaction with a pre-trained large language model. Through user studies and empirical experiments, we show that our approach generates explanations as helpful as those generated by a human domain expert while enabling beneficial interactions such as clarification and counterfactual queries.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/iros/poster_hu287f4bf22ec2383aeb9ca7cf03080f24_1052463_68faeddc9d31e60407e47948a4aa6c54.webp 400w,
               /post/iros/poster_hu287f4bf22ec2383aeb9ca7cf03080f24_1052463_3717e08a90413dbef78fb633338d7bc4.webp 760w,
               /post/iros/poster_hu287f4bf22ec2383aeb9ca7cf03080f24_1052463_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://xijia.me/post/iros/poster_hu287f4bf22ec2383aeb9ca7cf03080f24_1052463_68faeddc9d31e60407e47948a4aa6c54.webp&#34;
               width=&#34;760&#34;
               height=&#34;538&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Completed my journey as a Robotics Institute Summer Scholar</title>
      <link>https://xijia.me/post/riss/</link>
      <pubDate>Fri, 04 Aug 2023 00:00:00 +0000</pubDate>
      <guid>https://xijia.me/post/riss/</guid>
      <description>&lt;p&gt;During my time as a Robotics Institute Summer Scholar, I had the chance to interact with some of the coolest robots out there. Credit to the Boston Dynamics dog at Dr. Deepak Pathak&amp;rsquo;s lab, the Khephara IV robots at Dr. Katia Sycara&amp;rsquo;s lab, the autonomous driving car at Dr. John Dolan&amp;rsquo;s lab, and the snake robots at Dr. Howie Choset&amp;rsquo;s lab. In addition to these, I witnessed a variety of drones, robotic arms, and surgical robots, among others at other labs and the Field Robotics Center.&lt;/p&gt;
&lt;p&gt;This snake (left) literally crawled onto my leg. I was given the most unexpected leg massage of my life.&lt;/p&gt;
&lt;div id=&#34;image-table&#34;&gt;
    &lt;table&gt;
	    &lt;tr&gt;
    	    &lt;td style=&#34;padding:10px&#34;&gt;
        	    &lt;img src=&#34;snake_on_me.jpg&#34; width=&#34;350&#34;/&gt;
      	    &lt;/td&gt;
            &lt;td style=&#34;padding:10px&#34;&gt;
            	&lt;img src=&#34;snake.jpg&#34; width=&#34;300&#34;/&gt;
            &lt;/td&gt;
        &lt;/tr&gt;
    &lt;/table&gt;
&lt;/div&gt;
&lt;p&gt;This vehicle (left) won the second prize at the DARPA Grand Challenge. I learnt the story of how people from Stanford like to exhibit a picture of their car surpassing this one near the endpoint of the race.&lt;/p&gt;
&lt;div id=&#34;image-table&#34;&gt;
    &lt;table&gt;
	    &lt;tr&gt;
    	    &lt;td style=&#34;padding:10px&#34;&gt;
        	    &lt;img src=&#34;car.jpg&#34; width=&#34;350&#34;/&gt;
      	    &lt;/td&gt;
            &lt;td style=&#34;padding:10px&#34;&gt;
            	&lt;img src=&#34;smallcar.jpg&#34; width=&#34;350&#34;/&gt;
            &lt;/td&gt;
        &lt;/tr&gt;
    &lt;/table&gt;
&lt;/div&gt;
&lt;p&gt;We had so many Khephara IVs in our lab. I mainly worked with no. 117 and no. 119 and I miss them. The two octopuses in the photo were brought by me &amp;ndash; who can resist adding cute obstacles in robot experiments? I look forward to their reappearance in my future publications!&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/riss/octopus_hu638c8f8d346d691f1eab20b84f794b72_111350_4d4b71a010a52573231f270eee4f8a4c.webp 400w,
               /post/riss/octopus_hu638c8f8d346d691f1eab20b84f794b72_111350_698fc4fb771fc73d3dcd7ab93940f83f.webp 760w,
               /post/riss/octopus_hu638c8f8d346d691f1eab20b84f794b72_111350_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://xijia.me/post/riss/octopus_hu638c8f8d346d691f1eab20b84f794b72_111350_4d4b71a010a52573231f270eee4f8a4c.webp&#34;
               width=&#34;760&#34;
               height=&#34;570&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;I am immensely thankful to my mentors, peers, and the entire RISS community for their support and encouragement. As I move forward, I carry with me not only the knowledge and skills I have acquired but also the memories and friendships that will last a lifetime.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/riss/dog_hu08b44a1e1f6390d5f316a10cfddf50a7_220019_d96aacbf331d128fdbe42dc77cdcc0ab.webp 400w,
               /post/riss/dog_hu08b44a1e1f6390d5f316a10cfddf50a7_220019_074e77c0dc82ecab02d9f9074890766f.webp 760w,
               /post/riss/dog_hu08b44a1e1f6390d5f316a10cfddf50a7_220019_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://xijia.me/post/riss/dog_hu08b44a1e1f6390d5f316a10cfddf50a7_220019_d96aacbf331d128fdbe42dc77cdcc0ab.webp&#34;
               width=&#34;569&#34;
               height=&#34;760&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
